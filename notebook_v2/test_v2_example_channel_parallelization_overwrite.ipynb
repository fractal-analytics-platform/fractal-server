{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff005415-56e2-44e3-9329-17f9efc838a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run the illumination correction task after a custom init, which creates\n",
    "a parallelization list with different entries for different channels.\n",
    "\n",
    "NOTES:\n",
    "1. The illumination-correction task used here is illumination_correction_B,\n",
    "   which is only meant to run after the init_channel_paralllelization task.\n",
    "2. Within the current version, in the intermediate state (after the init\n",
    "   task) there exist the new empty images on-disk (in case of not\n",
    "   overwriting input images) but they do not exist in the image list. This\n",
    "   is consistent with the custom-parallelization-list execution branch (as\n",
    "   opposed to the default-filtering scenario, where the init task already\n",
    "   creates the new images in the image-list metadata).\n",
    "3. Because of the creation of on-disk images within the init task, also the\n",
    "   `overwrite_input` argument was moved from the actual\n",
    "   illumination-correction (parallel) task into the init task. Communication\n",
    "   with the parallel task takes place through an extra function argument\n",
    "   `raw_path`.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a221f15-142f-46b0-8f7d-e08e3b26301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary imports and auxiliary-function definition\n",
    "\n",
    "from pathlib import Path\n",
    "from devtools import debug\n",
    "import tempfile\n",
    "\n",
    "from fractal_server.app.runner.v2.models import Dataset, WorkflowTask\n",
    "from fractal_server.app.runner.v2.runner import execute_tasks_v2\n",
    "from fractal_server.images import SingleImage\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../tests/v2/04_runner\")\n",
    "from fractal_tasks_core_mock import TASK_LIST\n",
    "\n",
    "executor = ThreadPoolExecutor()\n",
    "\n",
    "\n",
    "def image_data_exist_on_disk(image_list: list[SingleImage]):\n",
    "    \"\"\"\n",
    "    Given an image list, check whether mock data were written to disk.\n",
    "    \"\"\"\n",
    "    prefix = \"[image_data_exist_on_disk]\"\n",
    "    all_images_have_data = True\n",
    "    for image in image_list:\n",
    "        if (Path(image.path) / \"data\").exists():\n",
    "            print(f\"{prefix} {image.path} contains data\")\n",
    "        else:\n",
    "            print(f\"{prefix} {image.path} does *not* contain data\")\n",
    "            all_images_have_data = False\n",
    "    return all_images_have_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73efec35-2572-4fe0-8107-107398d46ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarr_dir='/tmp/tmp52dbxn0l/zarr_dir'\n"
     ]
    }
   ],
   "source": [
    "# Create temporary directory for mocked zarrs\n",
    "tmp_path = Path(tempfile.mkdtemp())\n",
    "zarr_dir = (tmp_path / \"zarr_dir\").as_posix().rstrip(\"/\")\n",
    "print(f\"{zarr_dir=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642d1104-a5d4-4d29-8416-768cb6a96e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[create_ome_zarr] START\n",
      "[create_ome_zarr] image_dir='/tmp/input_images'\n",
      "[create_ome_zarr] zarr_dir='/tmp/tmp52dbxn0l/zarr_dir'\n",
      "[create_ome_zarr] zarr_path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr'\n",
      "[create_ome_zarr] END\n",
      "[yokogawa_to_zarr] START\n",
      "[yokogawa_to_zarr] path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr/A/01/0'\n",
      "[yokogawa_to_zarr] raw_path='/tmp/input_images/A_01_0.tif'\n",
      "[yokogawa_to_zarr] START\n",
      "[yokogawa_to_zarr] path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr/A/02/0'\n",
      "[yokogawa_to_zarr] raw_path='/tmp/input_images/A_02_0.tif'\n",
      "[yokogawa_to_zarr] END\n",
      "[yokogawa_to_zarr] END\n",
      "/tmp/ipykernel_135597/3454169311.py:14 <module>\n",
      "    dataset: Dataset(\n",
      "        id=None,\n",
      "        history=[None],\n",
      "        zarr_dir='/tmp/tmp52dbxn0l/zarr_dir',\n",
      "        images=[\n",
      "            SingleImage(\n",
      "                path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr/A/01/0',\n",
      "                attributes={\n",
      "                    'well': 'A01',\n",
      "                    'plate': 'my_plate.zarr',\n",
      "                    'data_dimensionality': 3,\n",
      "                },\n",
      "            ),\n",
      "            SingleImage(\n",
      "                path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr/A/02/0',\n",
      "                attributes={\n",
      "                    'well': 'A02',\n",
      "                    'plate': 'my_plate.zarr',\n",
      "                    'data_dimensionality': 3,\n",
      "                },\n",
      "            ),\n",
      "        ],\n",
      "        filters={\n",
      "            'plate': 'my_plate.zarr',\n",
      "            'data_dimensionality': 3,\n",
      "        },\n",
      "    ) (Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Run create_ome_zarr+yokogawa_to_zarr\n",
    "dataset = execute_tasks_v2(\n",
    "    wf_task_list=[\n",
    "        WorkflowTask(\n",
    "            task=TASK_LIST[\"create_ome_zarr_compound\"],\n",
    "            args_non_parallel=dict(image_dir=\"/tmp/input_images\"),\n",
    "        ),\n",
    "    ],\n",
    "    dataset=Dataset(zarr_dir=zarr_dir),\n",
    "    executor=executor,\n",
    ")\n",
    "\n",
    "# Print current dataset information\n",
    "debug(dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393b993b-8709-4f1e-8aff-9d15a3e512ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135597/479568765.py:21 <module>\n",
      "    dataset: Dataset(\n",
      "        id=None,\n",
      "        history=[\n",
      "            None,\n",
      "            None,\n",
      "            None,\n",
      "        ],\n",
      "        zarr_dir='/tmp/tmp52dbxn0l/zarr_dir',\n",
      "        images=[\n",
      "            SingleImage(\n",
      "                path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr/A/01/0',\n",
      "                attributes={\n",
      "                    'well': 'A01',\n",
      "                    'plate': 'my_plate.zarr',\n",
      "                    'data_dimensionality': 3,\n",
      "                    'illumination_correction': True,\n",
      "                },\n",
      "            ),\n",
      "            SingleImage(\n",
      "                path='/tmp/tmp52dbxn0l/zarr_dir/my_plate.zarr/A/02/0',\n",
      "                attributes={\n",
      "                    'well': 'A02',\n",
      "                    'plate': 'my_plate.zarr',\n",
      "                    'data_dimensionality': 3,\n",
      "                    'illumination_correction': True,\n",
      "                },\n",
      "            ),\n",
      "        ],\n",
      "        filters={\n",
      "            'plate': 'my_plate.zarr',\n",
      "            'data_dimensionality': 3,\n",
      "            'illumination_correction': True,\n",
      "        },\n",
      "    ) (Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Run init_channel_parallelization\n",
    "dataset = execute_tasks_v2(\n",
    "    wf_task_list=[\n",
    "        WorkflowTask(\n",
    "            task=TASK_LIST[\"illumination_correction_compound\"],\n",
    "            args_non_parallel=dict(overwrite_input=True),\n",
    "        ),\n",
    "    ],\n",
    "    dataset=dataset,\n",
    "    executor=executor,\n",
    ")\n",
    "\n",
    "# Check that custom parallelization_list\n",
    "assert len(dataset.images) == 2\n",
    "\n",
    "for image in dataset.images[0:2]:\n",
    "    assert image.attributes.get(\"illumination_correction\") is True\n",
    "\n",
    "\n",
    "# Print current dataset information\n",
    "debug(dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5f09a-a7d6-405f-9da4-542c2ec5fdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[illumination_correction_B] START\n",
      "[illumination_correction_B] path='/tmp/tmppm9uwfi7/zarr_dir/my_plate.zarr/A/01/0'\n",
      "[illumination_correction_B] raw_path='/tmp/tmppm9uwfi7/zarr_dir/my_plate.zarr/A/01/0'\n",
      "[illumination_correction_B] subsets={'C_index': 1}\n",
      "[illumination_correction_B] START\n",
      "[illumination_correction_B] path='/tmp/tmppm9uwfi7/zarr_dir/my_plate.zarr/A/02/0'\n",
      "[illumination_correction_B] raw_path='/tmp/tmppm9uwfi7/zarr_dir/my_plate.zarr/A/02/0'\n",
      "[illumination_correction_B] subsets={'C_index': 0}\n",
      "[illumination_correction] END\n",
      "[illumination_correction] END\n",
      "/tmp/ipykernel_116267/3866893277.py:16 <module>\n",
      "    dataset: Dataset(\n",
      "        id=None,\n",
      "        history=[\n",
      "            'create_ome_zarr',\n",
      "            'yokogawa_to_zarr',\n",
      "            'init_channel_parallelization',\n",
      "            'illumination_correction_B',\n",
      "        ],\n",
      "        images=[\n",
      "            SingleImage(\n",
      "                path='/tmp/tmppm9uwfi7/zarr_dir/my_plate.zarr/A/01/0',\n",
      "                attributes={\n",
      "                    'well': 'A01',\n",
      "                    'plate': 'my_plate.zarr',\n",
      "                    'data_dimensionality': 3,\n",
      "                    'illumination_correction': True,\n",
      "                },\n",
      "            ),\n",
      "            SingleImage(\n",
      "                path='/tmp/tmppm9uwfi7/zarr_dir/my_plate.zarr/A/02/0',\n",
      "                attributes={\n",
      "                    'well': 'A02',\n",
      "                    'plate': 'my_plate.zarr',\n",
      "                    'data_dimensionality': 3,\n",
      "                    'illumination_correction': True,\n",
      "                },\n",
      "            ),\n",
      "        ],\n",
      "        filters={\n",
      "            'plate': 'my_plate.zarr',\n",
      "            'data_dimensionality': 3,\n",
      "            'illumination_correction': True,\n",
      "        },\n",
      "        buffer=None,\n",
      "        parallelization_list=None,\n",
      "    ) (Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Run init_channel_parallelization\n",
    "dataset = execute_tasks_v2(\n",
    "    wf_task_list=[\n",
    "        WorkflowTask(\n",
    "            task=TASK_LIST[\"illumination_correction_B\"],\n",
    "        ),\n",
    "    ],\n",
    "    dataset=dataset,\n",
    "    executor=executor,\n",
    ")\n",
    "\n",
    "# Print current dataset information\n",
    "debug(dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22041b2-b03c-40e0-a1a8-299cb2bc6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
