"""Empty V1 tables

Revision ID: 8b2daaea466f
Revises: db09233ad13a
Create Date: 2025-01-29 15:55:53.215091

"""
import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = "8b2daaea466f"
down_revision = "db09233ad13a"
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("applyworkflow", schema=None) as batch_op:
        batch_op.drop_constraint(
            "fk_applyworkflow_output_dataset_id_dataset", type_="foreignkey"
        )
        batch_op.drop_constraint(
            "fk_applyworkflow_project_id_project", type_="foreignkey"
        )
        batch_op.drop_constraint(
            "fk_applyworkflow_workflow_id_workflow", type_="foreignkey"
        )
        batch_op.drop_constraint(
            "fk_applyworkflow_input_dataset_id_dataset", type_="foreignkey"
        )
        batch_op.drop_column("input_dataset_id")
        batch_op.drop_column("project_dump")
        batch_op.drop_column("first_task_index")
        batch_op.drop_column("workflow_id")
        batch_op.drop_column("log")
        batch_op.drop_column("status")
        batch_op.drop_column("slurm_account")
        batch_op.drop_column("output_dataset_id")
        batch_op.drop_column("input_dataset_dump")
        batch_op.drop_column("worker_init")
        batch_op.drop_column("last_task_index")
        batch_op.drop_column("end_timestamp")
        batch_op.drop_column("project_id")
        batch_op.drop_column("workflow_dump")
        batch_op.drop_column("working_dir_user")
        batch_op.drop_column("output_dataset_dump")
        batch_op.drop_column("user_email")
        batch_op.drop_column("start_timestamp")
        batch_op.drop_column("working_dir")

    with op.batch_alter_table("dataset", schema=None) as batch_op:
        batch_op.drop_constraint(
            "fk_dataset_project_id_project", type_="foreignkey"
        )
        batch_op.drop_column("meta")
        batch_op.drop_column("name")
        batch_op.drop_column("project_id")
        batch_op.drop_column("timestamp_created")
        batch_op.drop_column("read_only")
        batch_op.drop_column("history")
        batch_op.drop_column("type")

    with op.batch_alter_table("linkuserproject", schema=None) as batch_op:
        batch_op.add_column(sa.Column("id", sa.Integer(), nullable=False))
        batch_op.drop_constraint(
            "fk_linkuserproject_user_id_user_oauth", type_="foreignkey"
        )
        batch_op.drop_constraint(
            "fk_linkuserproject_project_id_project", type_="foreignkey"
        )
        batch_op.drop_column("user_id")
        batch_op.drop_column("project_id")

    with op.batch_alter_table("project", schema=None) as batch_op:
        batch_op.drop_column("timestamp_created")
        batch_op.drop_column("read_only")
        batch_op.drop_column("name")

    with op.batch_alter_table("resource", schema=None) as batch_op:
        batch_op.drop_constraint(
            "fk_resource_dataset_id_dataset", type_="foreignkey"
        )
        batch_op.drop_column("path")
        batch_op.drop_column("dataset_id")

    with op.batch_alter_table("state", schema=None) as batch_op:
        batch_op.drop_column("timestamp")
        batch_op.drop_column("data")

    with op.batch_alter_table("task", schema=None) as batch_op:
        batch_op.drop_constraint("uq_task_source", type_="unique")
        batch_op.drop_column("input_type")
        batch_op.drop_column("owner")
        batch_op.drop_column("args_schema")
        batch_op.drop_column("meta")
        batch_op.drop_column("name")
        batch_op.drop_column("args_schema_version")
        batch_op.drop_column("output_type")
        batch_op.drop_column("source")
        batch_op.drop_column("command")
        batch_op.drop_column("docs_link")
        batch_op.drop_column("version")
        batch_op.drop_column("docs_info")

    with op.batch_alter_table("workflow", schema=None) as batch_op:
        batch_op.drop_constraint(
            "fk_workflow_project_id_project", type_="foreignkey"
        )
        batch_op.drop_column("timestamp_created")
        batch_op.drop_column("name")
        batch_op.drop_column("project_id")

    with op.batch_alter_table("workflowtask", schema=None) as batch_op:
        batch_op.drop_constraint(
            "fk_workflowtask_workflow_id_workflow", type_="foreignkey"
        )
        batch_op.drop_constraint(
            "fk_workflowtask_task_id_task", type_="foreignkey"
        )
        batch_op.drop_column("workflow_id")
        batch_op.drop_column("meta")
        batch_op.drop_column("order")
        batch_op.drop_column("task_id")
        batch_op.drop_column("args")

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("workflowtask", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "args",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "task_id", sa.INTEGER(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "order", sa.INTEGER(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "meta",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "workflow_id",
                sa.INTEGER(),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.create_foreign_key(
            "fk_workflowtask_task_id_task", "task", ["task_id"], ["id"]
        )
        batch_op.create_foreign_key(
            "fk_workflowtask_workflow_id_workflow",
            "workflow",
            ["workflow_id"],
            ["id"],
        )

    with op.batch_alter_table("workflow", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "project_id", sa.INTEGER(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "name", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "timestamp_created",
                postgresql.TIMESTAMP(timezone=True),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.create_foreign_key(
            "fk_workflow_project_id_project", "project", ["project_id"], ["id"]
        )

    with op.batch_alter_table("task", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "docs_info", sa.VARCHAR(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "version", sa.VARCHAR(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "docs_link", sa.VARCHAR(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "command", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "source", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "output_type",
                sa.VARCHAR(),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "args_schema_version",
                sa.VARCHAR(),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "name", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "meta",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "args_schema",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "owner", sa.VARCHAR(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "input_type", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.create_unique_constraint("uq_task_source", ["source"])

    with op.batch_alter_table("state", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "data",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "timestamp",
                postgresql.TIMESTAMP(timezone=True),
                autoincrement=False,
                nullable=True,
            )
        )

    with op.batch_alter_table("resource", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "dataset_id", sa.INTEGER(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "path", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.create_foreign_key(
            "fk_resource_dataset_id_dataset", "dataset", ["dataset_id"], ["id"]
        )

    with op.batch_alter_table("project", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "name", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "read_only", sa.BOOLEAN(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "timestamp_created",
                postgresql.TIMESTAMP(timezone=True),
                autoincrement=False,
                nullable=False,
            )
        )

    with op.batch_alter_table("linkuserproject", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "project_id", sa.INTEGER(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "user_id", sa.INTEGER(), autoincrement=False, nullable=False
            )
        )
        batch_op.create_foreign_key(
            "fk_linkuserproject_project_id_project",
            "project",
            ["project_id"],
            ["id"],
        )
        batch_op.create_foreign_key(
            "fk_linkuserproject_user_id_user_oauth",
            "user_oauth",
            ["user_id"],
            ["id"],
        )
        batch_op.drop_column("id")

    with op.batch_alter_table("dataset", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column("type", sa.VARCHAR(), autoincrement=False, nullable=True)
        )
        batch_op.add_column(
            sa.Column(
                "history",
                postgresql.JSON(astext_type=sa.Text()),
                server_default=sa.text("'[]'::json"),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "read_only", sa.BOOLEAN(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "timestamp_created",
                postgresql.TIMESTAMP(timezone=True),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "project_id", sa.INTEGER(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "name", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "meta",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.create_foreign_key(
            "fk_dataset_project_id_project", "project", ["project_id"], ["id"]
        )

    with op.batch_alter_table("applyworkflow", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "working_dir", sa.VARCHAR(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "start_timestamp",
                postgresql.TIMESTAMP(timezone=True),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "user_email", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "output_dataset_dump",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "working_dir_user",
                sa.VARCHAR(),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "workflow_dump",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "project_id", sa.INTEGER(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "end_timestamp",
                postgresql.TIMESTAMP(timezone=True),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "last_task_index",
                sa.INTEGER(),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "worker_init", sa.VARCHAR(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "input_dataset_dump",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "output_dataset_id",
                sa.INTEGER(),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "slurm_account",
                sa.VARCHAR(),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "status", sa.VARCHAR(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column("log", sa.VARCHAR(), autoincrement=False, nullable=True)
        )
        batch_op.add_column(
            sa.Column(
                "workflow_id", sa.INTEGER(), autoincrement=False, nullable=True
            )
        )
        batch_op.add_column(
            sa.Column(
                "first_task_index",
                sa.INTEGER(),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "project_dump",
                postgresql.JSON(astext_type=sa.Text()),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "input_dataset_id",
                sa.INTEGER(),
                autoincrement=False,
                nullable=True,
            )
        )
        batch_op.create_foreign_key(
            "fk_applyworkflow_input_dataset_id_dataset",
            "dataset",
            ["input_dataset_id"],
            ["id"],
        )
        batch_op.create_foreign_key(
            "fk_applyworkflow_workflow_id_workflow",
            "workflow",
            ["workflow_id"],
            ["id"],
        )
        batch_op.create_foreign_key(
            "fk_applyworkflow_project_id_project",
            "project",
            ["project_id"],
            ["id"],
        )
        batch_op.create_foreign_key(
            "fk_applyworkflow_output_dataset_id_dataset",
            "dataset",
            ["output_dataset_id"],
            ["id"],
        )

    # ### end Alembic commands ###
