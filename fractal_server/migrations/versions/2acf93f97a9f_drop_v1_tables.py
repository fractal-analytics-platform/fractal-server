"""Drop V1 tables

Revision ID: 2acf93f97a9f
Revises: db09233ad13a
Create Date: 2025-01-29 14:04:24.442170

"""
import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = "2acf93f97a9f"
down_revision = "db09233ad13a"
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("task")
    op.drop_table("state")
    op.drop_table("applyworkflow")
    op.drop_table("project")
    op.drop_table("workflow")
    op.drop_table("workflowtask")
    op.drop_table("dataset")
    op.drop_table("resource")
    op.drop_table("linkuserproject")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "linkuserproject",
        sa.Column(
            "project_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "user_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.ForeignKeyConstraint(
            ["project_id"],
            ["project.id"],
            name="fk_linkuserproject_project_id_project",
        ),
        sa.ForeignKeyConstraint(
            ["user_id"],
            ["user_oauth.id"],
            name="fk_linkuserproject_user_id_user_oauth",
        ),
        sa.PrimaryKeyConstraint(
            "project_id", "user_id", name="pk_linkuserproject"
        ),
    )
    op.create_table(
        "resource",
        sa.Column("path", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "dataset_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.ForeignKeyConstraint(
            ["dataset_id"],
            ["dataset.id"],
            name="fk_resource_dataset_id_dataset",
        ),
        sa.PrimaryKeyConstraint("id", name="pk_resource"),
    )
    op.create_table(
        "dataset",
        sa.Column(
            "meta",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("type", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "read_only", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('dataset_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column(
            "project_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "history",
            postgresql.JSON(astext_type=sa.Text()),
            server_default=sa.text("'[]'::json"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "timestamp_created",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["project_id"],
            ["project.id"],
            name="fk_dataset_project_id_project",
        ),
        sa.PrimaryKeyConstraint("id", name="pk_dataset"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "workflowtask",
        sa.Column(
            "meta",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "args",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "workflow_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "task_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.Column("order", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.ForeignKeyConstraint(
            ["task_id"], ["task.id"], name="fk_workflowtask_task_id_task"
        ),
        sa.ForeignKeyConstraint(
            ["workflow_id"],
            ["workflow.id"],
            name="fk_workflowtask_workflow_id_workflow",
        ),
        sa.PrimaryKeyConstraint("id", name="pk_workflowtask"),
    )
    op.create_table(
        "workflow",
        sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('workflow_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column(
            "project_id", sa.INTEGER(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "timestamp_created",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["project_id"],
            ["project.id"],
            name="fk_workflow_project_id_project",
        ),
        sa.PrimaryKeyConstraint("id", name="pk_workflow"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "project",
        sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column(
            "read_only", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('project_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column(
            "timestamp_created",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name="pk_project"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "applyworkflow",
        sa.Column(
            "start_timestamp",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "end_timestamp",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "worker_init", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "project_id", sa.INTEGER(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "input_dataset_id",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "output_dataset_id",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "workflow_id", sa.INTEGER(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "working_dir", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "working_dir_user",
            sa.VARCHAR(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("status", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("log", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "first_task_index",
            sa.INTEGER(),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "last_task_index",
            sa.INTEGER(),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "workflow_dump",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "user_email", sa.VARCHAR(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "input_dataset_dump",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "output_dataset_dump",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "slurm_account", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "project_dump",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["input_dataset_id"],
            ["dataset.id"],
            name="fk_applyworkflow_input_dataset_id_dataset",
        ),
        sa.ForeignKeyConstraint(
            ["output_dataset_id"],
            ["dataset.id"],
            name="fk_applyworkflow_output_dataset_id_dataset",
        ),
        sa.ForeignKeyConstraint(
            ["project_id"],
            ["project.id"],
            name="fk_applyworkflow_project_id_project",
        ),
        sa.ForeignKeyConstraint(
            ["workflow_id"],
            ["workflow.id"],
            name="fk_applyworkflow_workflow_id_workflow",
        ),
        sa.PrimaryKeyConstraint("id", name="pk_applyworkflow"),
    )
    op.create_table(
        "state",
        sa.Column(
            "data",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "timestamp",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.PrimaryKeyConstraint("id", name="pk_state"),
    )
    op.create_table(
        "task",
        sa.Column(
            "meta",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("source", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column(
            "command", sa.VARCHAR(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "input_type", sa.VARCHAR(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "output_type", sa.VARCHAR(), autoincrement=False, nullable=False
        ),
        sa.Column("owner", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("version", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "args_schema",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "args_schema_version",
            sa.VARCHAR(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "docs_info", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "docs_link", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.PrimaryKeyConstraint("id", name="pk_task"),
        sa.UniqueConstraint("source", name="uq_task_source"),
    )
    # ### end Alembic commands ###
